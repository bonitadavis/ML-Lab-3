{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Two: Exploring Image Data\n",
    "\n",
    "***Christopher Cook, Bonita Davis, Anekah Kelley, Davis Lynn***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Business Understanding**\n",
    "\n",
    "This is a dataset of 15,149 songs from 3,083 artists over the course of over a century (1899-2024).  It is sorted by 18 different features:\n",
    "*    Track (string)\n",
    "*    Artist (string)\n",
    "*    Year (int)\n",
    "*    Duration (int, in ms)\n",
    "*    Time Signature (int, numerator of time signature; i.e. 4 means 4/4)\n",
    "*    Danceability (float, 0-10)\n",
    "*    Energy (float 0-1)\n",
    "*    Key (int, 0-11; 0 = C, etc.)\n",
    "*    Loudness (float, loudness in db -47.4=0.92)\n",
    "*    Mode (int, major/minor modality; 0/1)\n",
    "*    Speechiness (float, 0-1)\n",
    "*    Acousticness (float, 0-1)\n",
    "*    Instrumentalness (float 0-1)\n",
    "*    Liveness (float, 0-1)\n",
    "*    Valence (float, 0-1)\n",
    "*    Tempo (tempo, BPM from 0-220)\n",
    "*    Popularity (int, 0-100)\n",
    "*    Genre (string)\n",
    "\n",
    "This data was collected directly from the Spotify API, allowing for additional attributes such as Loudness, Speechiness, etc. The dataset is free to download on Kaggle through the link below.\n",
    "\n",
    "Data Source: https://www.kaggle.com/datasets/thebumpkin/10400-classic-hits-10-genres-1923-to-2023/data\n",
    "\n",
    "The task of this dataset is to serve as a touchpoint for individuals in the music industry to explore trends, compare genres, analyze sonic qualities, and see how classic hits across time periods and genres compare to once another (Kaggle).  The sheer size of the dataset, along with the amount of information provided about each song, makes this an excellent resource to understand musical trends.  It can also be used to see how an individual artist or genre has performed over time, providing insights into how future songs/albums might perform.\n",
    "\n",
    "This is the primary business-case of this dataset and our classifier -- attempting to predict attributes about songs.  This information can be used by companies like Spotify and Apple Music to predict the likelihood that a user will like a song based on the attributes of the songs they have been previously shown to like (if they typically like pop music with a loudness of 97, that information can be used to predict new songs that they may also like).  These businesses care more about the relationships between all of the attributes, as it is the combination of these attributes that creates a listening style.  This information could also be used by a music producer or musician to determine what attributes about songs in different genres/time periods tend to make them popular in order to see how to best leverage the artist's skills to create a hit song.  These businesses care more about the interplay between the attributes that they deem to be relevant based on the artist and popularity, as that gives the best blueprint for success.\n",
    "\n",
    "This model would likely be deployed, although it may differ depending on the user.  Users like Spotify, Apple Music, YouTube Music, and other such companies would use this data constantly, making it a deployed model.  In contrast, while some music producers may consistently run new models, it is possible that it could be semi-offline and just generated once for the relevant artists.  This data was likely collected with these intentions in mind, as classifiers could be trained and sold to such businesses for a sizeable amount of money.\n",
    "\n",
    "The use of such a classifier by companies like Spotify and Apple Music is supported by the fact that Spotify currently uses a similar classifier to create their \"Made For You\" playlist provided to users (https://www.music-tomorrow.com/blog/how-spotify-recommendation-system-works-a-complete-guide-2022).  They use very similar attributes (which is the case because our dataset directly incorporates Spotify information) to predict the likelihood that a user will enjoy a song based on their listening history.  Spotify's algorithm is many times more complex than anything we would be capable of creating at this point in time, so holding ourselves to that standard would be simply foolish.  Additionally, Spotify does not publish an \"accuracy\" rate for predicting songs.  Further complicating the problem, an NIH study showed that roughly 15% of people skip songs that they haven't listened to, before even listening to it, and that others skipped the songs shortly after starting them if they didn't quickly enjoy the song (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7004375/).  While this is a relatively small percentage, it shows the importance of a very accurate classifier.  Ideally, a classifier with a roughly 90% accuracy is likely possible with advanced algorithms, predicts songs with an acceptable margin of error, and will result in benefits for companies.\n",
    "\n",
    "For music producers and artists interested in predicting the success of their songs, a much lower bar of accuracy is acceptable.  Similar classifier algorithms boast an accuracy of anywhere between 55-77% (https://cs229.stanford.edu/proj2015/140_report.pdf, https://towardsdatascience.com/song-popularity-predictor-1ef69735e380, https://www.nature.com/articles/s41598-022-25430-9).  In truth, anything able to predict with an accuracy greater than 50% would be considered successful to some degree, as popularity is highly subjective, changes dramatically over time, and is often a product of purely qualitative features that are difficult to connect to quantitative information, despite best efforts.  Aiming for an accuracy of roughly 65% would put our model squarely in the middle of currently available algorithms, making it both realistic and acceptable in the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preparation of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Training/Testing Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expit\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import plotly\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_intercept(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_intercept=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_intercept(X) if add_intercept else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "\n",
    "\n",
    "    @property\n",
    "    def coef_(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return self.w_[1:]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def intercept_(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return self.w_[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_intercept=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_intercept(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self, X, y):\n",
    "        # Ensure y is numeric, converting categorical to integers or floats\n",
    "        y = y.astype('float')  # or y = y.astype('int') if appropriate\n",
    "    \n",
    "        ydiff = y - self.predict_proba(X, add_intercept=False).ravel()  # Get y difference\n",
    "        ydiff = np.array(ydiff)  # Convert ydiff to a NumPy array to allow multi-dimensional indexing\n",
    "        gradient = np.mean(X * ydiff[:, np.newaxis], axis=0)  # Multiply ydiff as a column vector\n",
    "\n",
    "        return gradient.reshape(self.w_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "\n",
    "    @property\n",
    "    def coef_(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return self.w_[:,1:]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def intercept_(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return self.w_[:,0]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,\n",
    "                                                 self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ClassicHit.csv')\n",
    "\n",
    "#This is how I (Chris) believe the train/test data should be done\n",
    "\n",
    "Xcoloumns = ['Year', 'Duration', 'Time_Signature', 'Danceability', 'Energy', 'Key', 'Loudness', 'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo']\n",
    "\n",
    "X = df[Xcoloumns]\n",
    "y = pd.cut(df['Popularity'], bins=[-float('inf'), 15, 75, float('inf')], labels=[0, 1, 2]) #I am choosing the splits to determine whether a song will be, not populary at all, mediocre, very popular\n",
    "#I chose this way so we can find something meaningful no matter what the classification is for the songs\n",
    "#y = (df['Popularity'] > 75).astype(int) #Testing for binary case\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size=0.2)\n",
    "\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "\n",
    "graph1 = {'x': np.unique(y),\n",
    "          'y': np.bincount(y)/len(y),\n",
    "            'type': 'bar'}\n",
    "\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Class Distribution',\n",
    "                'autosize':False,\n",
    "                'width':400,\n",
    "                'height':400}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(0.1,500)\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr)\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exceptional Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
